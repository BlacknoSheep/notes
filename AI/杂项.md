# 大模型微调方法

https://zhuanlan.zhihu.com/p/621700272

# MDP和OMDP的区别

**chatgpt:**

Markov Decision Process (MDP) 和 Online Markov Decision Process (Online MDP) 都是用于建模决策问题的数学框架，但它们之间存在一些关键的区别。

1. **定义和性质**：
   - **Markov Decision Process (MDP)**: 是一个经典的数学框架，用于描述具有马尔可夫性质的决策问题。MDP 包含状态空间、动作空间、状态转移概率、奖励函数等元素，它假定系统的未来状态只依赖于当前状态和执行的动作。
   - **Online Markov Decision Process (Online MDP)**: 是对传统 MDP 的扩展，用于处理动态环境和在线决策问题。在Online MDP中，决策者需要在每个时刻实时地进行决策，而不是预先知道环境的统计性质。这意味着系统的状态转移和奖励可能是随机的，而决策者需要实时地适应变化。
2. **时间顺序**：
   - **MDP**: 通常被用于描述离散时间点上的决策问题，其中系统在每个时间步骤都会执行一个动作，然后转移到下一个状态。
   - **Online MDP**: 更强调在连续时间或非确定性时间步骤上做出实时决策。这意味着 Online MDP 更适合描述那些在决策者做出决策时环境可能变化的情境。
3. **信息利用**：
   - **MDP**: 决策者通常可以事先获得关于状态转移和奖励的完整信息，可以通过动态规划等方法来找到最优策略。
   - **Online MDP**: 决策者可能只能获得有限的、实时的信息，需要采用在线学习或强化学习等方法来适应环境的不确定性。

总的来说，Online MDP 是对标准 MDP 的扩展，更适用于描述那些在决策时环境可能动态变化的实际问题。在Online MDP中，决策者需要实时地采集信息并调整策略，以适应环境的不确定性。